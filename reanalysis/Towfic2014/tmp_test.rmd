test
========================================================

`r as.character(Sys.time())`
<br/>
<br/>

### Overview

Test.

library(knitr)
knit2html("tmp_test.rmd")

```{r runparameters, results='hide', echo=FALSE}
starttime = Sys.time()
debug = FALSE
downloaddata=FALSE
set.seed(100)
```

<br/>
<br/>

```{r, results='hide', message=FALSE}
includelibs = c("sva", "limma", "xtable")
tmp=lapply(includelibs, require, character.only=T)
if(any(!unlist(tmp)))
{
  stop( paste("Not able to find all packages. Please install ",
              paste(includelibs[!unlist(tmp)], collapse=", ") )
              )
  #source("http://bioconductor.org/biocLite.R")
  #biocLite(includelibs)
}
source("../../commonscripts/helperfunctions.r")
rm(tmp)
```

The above libraries and helper script files are needed in order to reproduce this report.
<br/>
<br/>

### Getting the data

The important sample information is described in Table S1 from Towfic et al. and its usage in ComBat is described briefly in the methods;

>  Each microarray’s chip designation was supplied a batch label; there were 18 batches in all. The labels for the treatments (i.e. drug product, reference standard…) were added as covariates.<cite> Towfic et al.

Table S1 does have a "Chip"- column, unfortunately there is no dedicated "treatment"-column.
Communication with the corresponding author yielded this explanation

> ..and the only thing we used as a covariate was the unique treatment names themselves (e.g. "Medium"" or "RS").<cite> Towfic et al.

Based on these descriptions and the annotation for the GEO deposit, we compiled a more complete sample annotation file (sampleannotation.csv).

```{r results="asis"}
sampleannotation = read.table("data/sampleannotation.csv", sep="\t", header=TRUE,  stringsAsFactors=FALSE)
sampleannotation$code = make.names(sampleannotation$code)
sampleannotation$chip = as.character(sampleannotation$chip)
dimnames(sampleannotation)[[1]] = sampleannotation$code

print.xtable(xtable ( head(sampleannotation), caption="Head of sampleannotation"), 
			comment = TRUE,
      type = "html",
      html.table.attributes=c("CELLPADDING=3, BORDER=1"),
      include.rownames = TRUE)
```

<br/>

The "covariate"-column is made based on the "code"-column, but might not match 100% to what was actually used for all samples. The last two columns are from the GEO deposit and reveal the samples that do not have data, which we will remove from the data shortly.

The naming convention seems to differ slightly between the Table S1 and the text in Towfic et al. This is our interpretation of the main covariate labels and its corresponding name in the text.

- **DP** referred to as GA (but not GA as in table S1)
- **N** referred to as "generic"
- **M** referred to as "medium"
- **RS** referred to as "reference standard""

```{r}
# take out 3 samples that are not assigned to a geoaccession. Failed QC?
sampleannotation = sampleannotation[!is.na(sampleannotation$geoaccession),] 
```

The batch/covariate design shows many batches and covariate groups.

```{r results='asis'}
print.xtable(xtable ( table(sampleannotation[, c("chip", "covariate")]), caption="Number of samples per batch/covariate combo. Chip barcode in rows, covariate in columns"), 
			comment = TRUE,
      type = "html",
      html.table.attributes=c("CELLPADDING=3, BORDER=1"),
      include.rownames = TRUE)
```

<br/>
<br/>

A look at the primary comparison, "DP"(GA) and "N"(generic) reveals a lack of balance.

```{r results='asis'}

print.xtable(xtable ( table(sampleannotation[sampleannotation$covariate %in% c("DP", "N"),
										c("chip", "covariate")]),), 
			comment = TRUE,
      type = "html",
      html.table.attributes=c("CELLPADDING=3, BORDER=1"),
      include.rownames = TRUE)
```

<br/>
<br/>


> The microarray data have been deposited in the Gene Expression Omnibus, under accession number [GSE40566](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE40566). <cite> Towfic et al.

The processed data from the above GEO deposit ("Series Matrix File") is from another publication which did not processes the data as described in Towfic et al. (personal communication). The lesser processed data in GEO linked to as [GSE40566_non_normalized.txt.gz](http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file&file=GSE40566%5Fnon%5Fnormalized%2Etxt%2Egz) in the "Supplementary file" section was thus used in this report.

Probe annotation was also found in the "Supplementary file" section as [GSE40566_RAW.tar](http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file).

A recap of the important input files used in this report:

- **sampleannotation.csv** holds the important sample/batch/covariate assignment. Compiled based on information in Towfic et al, the GEO deposit and personal communication.
- **GSE40566_non_normalized.txt** the measurements in a sample vs probe matrix. From the [GEO deposit](http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file&file=GSE40566%5Fnon%5Fnormalized%2Etxt%2Egz). Not in github.
- **GPL6887_MouseWG-6_V2_0_R3_11278593_A.txt** the probe annotation needed for the data row to probe to gene matching. From the GEO deposit inside the [GSE40566_RAW.tar](http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file). Not in github.

Reading the data.

```{r}
if(downloaddata)
{
  temp = tempfile()
  download.file(url="http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file&file=GSE40566%5Fnon%5Fnormalized%2Etxt%2Egz",
              destfile=temp, mode = "wb")
  rawdata = read.table(temp, sep="\t", header=TRUE, stringsAsFactors=FALSE)
  unlink(temp)
  
  temp = tempfile()
  download.file(url="http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file",
              destfile=temp, mode = "wb")
  tardirtemp = file.path(tempdir(), "annottmp")
  dir.create(tardirtemp)
  untar(temp, exdir = tardirtemp, tar="internal")
  rawannotation = read.table(paste(tardirtemp ,"/GPL6887_MouseWG-6_V2_0_R3_11278593_A.txt.gz", sep=""), 
                             sep="\t", header=TRUE, stringsAsFactors=FALSE, 
                             skip=8, comment.char="", quote="", fill=TRUE)
  
  unlink(temp)
  unlink(tardirtemp, recursive=TRUE )
}else{
  
  # if download did not work change downloaddata to FALSE  
  # download data from the GEO deposit
  # unpack and place files in a folder named "not_in_github"
  rawdata = read.table("not_in_github/GSE40566_non_normalized.txt", 
                       sep="\t", header=TRUE, stringsAsFactors=FALSE)

  # the probe annotation file found inside GSE40566_RAW.tar
  rawannotation = read.table("not_in_github/GPL6887_MouseWG-6_V2_0_R3_11278593_A.txt.gz", 
                             sep="\t", header=TRUE, stringsAsFactors=FALSE, 
                             skip=8, comment.char="", quote="", fill=TRUE)
}
```

Some formatting is needed to match the probe information to the measurements and the measurements to the sample information.

```{r tidy=FALSE}
# annotation file has two separate tables, one for experimental and one at the end for controls.
# splitting and fixing the tables:
tmp =  rawannotation$Species=="Mus musculus"
experimentalannot = rawannotation[tmp,]
experimentalannot$Array_Address_Id = as.numeric(experimentalannot$Array_Address_Id)
controlannot = rawannotation[!tmp,]
dimnames(controlannot)[[2]] = rawannotation[rawannotation[,2]=="Array_Address_Id",]
controlannot$Array_Address_Id = suppressWarnings(as.numeric(controlannot$Array_Address_Id))
controlannot = controlannot[!is.na(controlannot$Array_Address_Id),]
controlannot=controlannot[,1:6]
probeannotation = merge(experimentalannot, controlannot, all=TRUE )
#dim(probeannotation)
rm(tmp, experimentalannot, controlannot)

probeannotation = probeannotation[!duplicated(probeannotation$Array_Address_Id),]
probeannotation = probeannotation[probeannotation$Array_Address_Id %in% rawdata$ID_REF, ] # 
probeannotation$Symbol=tolower(probeannotation$Symbol)
dimnames(probeannotation)[[1]] = probeannotation$Probe_Id
#dim(probeannotation)

#sort and filter probe and data similarly.
datamatrix_raw = as.matrix(rawdata[,-1])
datamatrix_raw = datamatrix_raw[match( probeannotation$Array_Address_Id , rawdata$ID_REF), ]
dimnames(datamatrix_raw)[[1]] = probeannotation$Probe_Id
#dim(datamatrix_raw)
#dim(probeannotation)

#and match data to samples.
#table(sampleannotation$code %in% dimnames(datamatrix_raw)[[2]])# check
#table(dimnames(datamatrix_raw)[[2]] %in% sampleannotation$code)# check
datamatrix_raw = datamatrix_raw[, match(sampleannotation$code , dimnames(datamatrix_raw)[[2]])]
```

Several tables with results are presented in the Supporting Information in Towfic et al. We are aiming to reproduce two of these. Unfortunately, they were only presented in a pdf-format not easily parsed by a computer. We had to resort to an ad hoc method of cut-and-paste from pdf into text files which were somewhat polluted by pdf-formatting code. For some tables, about 10% of the rows will be lost, but the rest will suffice for our purpose.

```{r}
# Table S2
table_s2 = read.table("data/table_s2.csv", sep="\t", header=TRUE, stringsAsFactors=FALSE, fill=TRUE)
table_s2 = as.matrix(table_s2)
table_s2[,3:6] = as.numeric(table_s2[,3:6])
# not able to paste the pdf whitout a lot of gibberish clutter the data. Some probes are lost!
a =rowSums(is.na(table_s2[,3:6])) > 0
print(paste("Lost rows table s2: ", sum(a)))
table_s2=data.frame(table_s2[!a,], stringsAsFactors=FALSE)
# data.frame makes the columns characters again.
for(n in 3:6)
{
  table_s2[,n]=as.numeric(table_s2[,n])
}

# Table S5
table_s5 = read.table("data/table_s5.csv", sep="\t", header=TRUE, stringsAsFactors=FALSE, fill=TRUE)
tmp = as.matrix(table_s5)
tmp[,3:14] = as.numeric(tmp[,3:14])
# not able to paste the pdf whitout a lot of gibberish clutter the data. Some probes are lost!
a =rowSums(is.na(tmp[,3:14])) > 0
print(paste("Lost rows table s5: ", sum(a)))
table_s5=data.frame(table_s5[!a,], stringsAsFactors=FALSE)
table_s5$Fold_Change = as.numeric(table_s5$Fold_Change)

```
<br/>
<br/>

Alternative raw data set, the one that was actually used.
```{r}
alt_annot = read.table("not_in_github/FORGEO_master_matrix_PLOS_ONE_response.csv", sep="\t", header=FALSE, stringsAsFactors=FALSE, fill=TRUE, nrows=6)
alt_annot=t(alt_annot[,c(-1,-2)])
colnames(alt_annot) = alt_annot[1,]
alt_annot=alt_annot[-1,]
alt_annot=as.data.frame(alt_annot, stringsAsFactors=FALSE)
#need to split arrayid slot and the last number 1or2 which might be alternative raw data for the same hyb or something else.
tmp = data.frame(do.call('rbind', strsplit(alt_annot[, "Array Address ID"],'_')), stringsAsFactors=FALSE)
alt_annot$slot=tmp[,2]
alt_annot$somenumber=tmp[,3]



alt_data=read.table("not_in_github/FORGEO_master_matrix_PLOS_ONE_response.csv", sep="\t", header=TRUE, stringsAsFactors=FALSE, fill=TRUE, skip=5)
rownames(alt_data)=alt_data[,2]
alt_data = alt_data[,c(-1,-2,-3)]
alt_data = as.matrix(alt_data)

#the data seem to have two rows for each hyb.
alt_data1 = alt_data[,((1:107) *2) -1]
alt_data2 = alt_data[,((1:107) *2)]
alt_annot1 = alt_annot[((1:107) *2) -1,]
alt_annot2 = alt_annot[((1:107) *2) ,]
sum(alt_annot1$Chip == alt_annot2$Chip)
sum(alt_annot1$slot == alt_annot2$slot)

dim(alt_data1)
dim(datamatrix_raw)
# not similar dims, and the naming convension for the samples differ.

#making the alt_data have the same dim and colnames as datamatrix_raw
a = paste(alt_annot1$Chip, alt_annot1$slot) 
b = paste(sampleannotation$chip, sampleannotation$slot) 
ind = match(b,a)
alt_annot1 = alt_annot1[ind,]
alt_annot1 = alt_annot1[!is.na(alt_annot1$Chip),]
alt_annot2 = alt_annot2[ind,]
alt_annot2 = alt_annot2[!is.na(alt_annot2$Chip),]

sum(alt_annot1$Chip == alt_annot2$Chip)
sum(alt_annot1$slot == alt_annot2$slot)

sum(alt_annot1$Chip == sampleannotation$chip)
sum(alt_annot1$slot == sampleannotation$slot)

sum(colnames(datamatrix_raw)==rownames(sampleannotation))

alt_data1 = alt_data1[, match(paste( "X", alt_annot1[,"Array Address ID"], sep=""), colnames(alt_data1))]
alt_data2 = alt_data2[, match(paste( "X", alt_annot2[,"Array Address ID"], sep=""), colnames(alt_data2))]

colnames(alt_data1) = colnames(datamatrix_raw)
colnames(alt_data2) = colnames(datamatrix_raw)

table(rownames(datamatrix_raw) %in% rownames(alt_data1)) # all from the first are present. 

alt_data1 = alt_data1[match(rownames(datamatrix_raw), rownames(alt_data1)), ]
alt_data2 = alt_data2[match(rownames(datamatrix_raw), rownames(alt_data2)), ]

# now all datamatrices are sorted similar
n=1
cor(alt_data1[,n], alt_data2[,10])
cor(alt_data1[,n], datamatrix_raw[,n])

#boxplot(alt_data1[1:1000,])
#boxplot(alt_data2[1:1000,])
#boxplot(datamatrix_raw[1:1000,])
cormatrix=matrix(ncol=5, nrow=ncol(datamatrix_raw))
colnames(cormatrix) = c("alt1_vs_alt2", "alt1_vs_GSE40566", "alt2_vs_GSE40566", "mincol", "maxcol")
for(i in 1:ncol(datamatrix_raw))
{
  cormatrix[i, 1]= cor(alt_data1[,i], alt_data2[,i])
  cormatrix[i, 2]= cor(alt_data1[,i], datamatrix_raw[,i])
  cormatrix[i, 3]= cor(alt_data2[,i], datamatrix_raw[,i])
  cormatrix[i, 4] = match(min(cormatrix[i,1:3]), cormatrix[i,1:3])
  cormatrix[i, 5] = match(max(cormatrix[i,1:3]), cormatrix[i,1:3])
}
#cbind(cormatrix, alt_annot1$somenumber)

x =(datamatrix_raw >= alt_data2) + (datamatrix_raw <= alt_data1)

xmean = (alt_data1 +  alt_data2)/2
diffx = xmean - datamatrix_raw


```


### Reproduce some of the original results

Towfic et al. performed several different tests for these data, and it is outside the scope of this report to reproduce all of their results. We focus on the key part of testing for differentially expressed genes between "GA" (DP) and "generic"(N) as described in Table S2 and Table S5. But prior to those tests, we have to preprocess according to the description.

> Starting with background-corrected bead-level signals, we quantile normalized the extracted data for all samples across all 46,547 probes via the “preprocessCore” package in R. <cite> Towfic et al.

```{r}
datamatrices = list()
#datamatrices[["real_raw"]] = datamatrix_raw
datamatrices[["real_raw"]] = xmean
if(debug)
{
  datamatrices[["real_raw"]] = datamatrix_raw[1:1000,]
  table_s2 = table_s2[table_s2$ID %in% rownames(datamatrices[["real_raw"]]),]
  table_s5 = table_s5[table_s5$Probe %in% rownames(datamatrices[["real_raw"]]), ]
}
datamatrices[["real_qnorm"]] = normalizeBetweenArrays(datamatrices[["real_raw"]], method="quantile")
# normalize.quantiles from the package preprocessCore is used in the paper, but seems to do the same as the limma version.
```

> We then corrected for batch variation with ComBat [17] as implemented in the SVA package of R [18]. Each microarray’s chip designation was supplied a batch label; there were 18 batches in all. The labels for the treatments (i.e. drug product, reference standard…) were added as covariates. <cite> Towfic et al.

```{r}
combatmod = model.matrix(~as.factor(sampleannotation$covariate))
datamatrices[["real_combat_covariates"]]= as.matrix(ComBat(dat=datamatrices[["real_qnorm"]],
                                                           batch=sampleannotation$chip,
                                                           mod=combatmod,
                                                           numCovs=NULL,
                                                           par.prior=TRUE,
                                                           prior.plots=FALSE))

```

<br/>
<br/>

**Table S2**

First we will try to reproduce Table S2.

> Genes utilized for the tolerance method illustrated in Figure 1B. <cite> Towfic et al.(figure text)

> This standard of comparison was constructed by first identifying the top 1000 probes by absolute fold change of reference standard compared to the medium (Table S2). The list includes both upregulated and downregulated probes compared to medium. Probes were filtered such that ones upregulated by reference standard needed to have an average reference standard expression of 6.00 or higher and ones downregulated by reference standard needed to have an average medium expression of 6.00 or higher. <cite> Towfic et al.

This is how the table looks

```{r results='asis'}


print.xtable(xtable ( head(table_s2), caption="Head of Table S2"), 
			comment = TRUE,
      type = "html",
      html.table.attributes=c("CELLPADDING=3, BORDER=1"),
      include.rownames = TRUE)

```

```{r}
thiscovariatename = "covariate"
thisdata = datamatrices[["real_combat_covariates"]]

# the mean uses log2 numbers and will be a geometric mean.
meanM = rowMeans(thisdata[, sampleannotation[, "covariate"]=="M"]) 
meanRS = rowMeans(thisdata[, sampleannotation[, "covariate"]=="RS"]) 
meanDP = rowMeans(thisdata[, sampleannotation[, "covariate"]=="DP"])
meanN = rowMeans(thisdata[, sampleannotation[, "covariate"] =="N"]) 
rm(thisdata)
foldchange_RS_vs_M = meanRS - meanM
foldchange_RS_vs_M = foldchange_RS_vs_M[meanM>6 | meanRS>6]
top1000_RS_vs_M = names(foldchange_RS_vs_M[order(abs(foldchange_RS_vs_M), decreasing=TRUE)])[1:1000]
table(table_s2$ID %in% top1000_RS_vs_M)
```

Out of Table S2's **`r nrow(table_s2)`** probes, **`r sum(table_s2$ID %in% top1000_RS_vs_M)`** were reproduced. Scatter plots of the actual values show a correlation.

```{r reproduced_tables2, dev='png', fig.width=8, fig.height=8, fig.show='hold', tidy=FALSE}
# scatter plot correlation of the 4 columns in table_S2 vs. the reproduced numbers.
par(mfrow=c(2, 2))
plot(table_s2$AVG_Medium, meanM[table_s2$ID], pch=".")
plot(table_s2$AVG_Reference_Standard, meanRS[table_s2$ID], pch=".")
plot(table_s2$AVG_GA, meanDP[table_s2$ID], pch=".")
plot(table_s2$AVG_generic, meanN[table_s2$ID], pch=".")
```

Original values from table S2 on X-axis, reproduced values on Y-axis. The values in Table S2 is almost reproduced.

<br/>
<br/>

**Table S5**

This is how the table looks. It is transposed and shows only the top 3 genes for visualization purposes.

```{r results="asis"}

print.xtable(xtable (t(table_s5[1:3,]), caption="top of Table_S5"), 
			comment = TRUE,
      type = "html",
      html.table.attributes=c("CELLPADDING=3, BORDER=1"),
      include.rownames = TRUE)

```

<br/>
<br/>

> Comparison of expression in GA to expression in GA for each probe, including fold change, ANOVA, LIMMA with background subtraction, comparative marker selection by signal-to-noise ratio, comparative marker selection by t-test, and the Wilcoxon non-parametric method. <cite> Figure text, Towfic et al.

There must be a typo in the figure text, they meant "Comparison of expression in GA to expression in **generic** for each probe, ...".

> To find differentially expressed probes between generic and GA, we utilized various statistical tests at the probe level and merged the results across the different methods. <cite> Towfic et al.

How the fold change was calculated is not explained. A common way is to take the difference of geometric means that were calculated for Table S2 above.

```{r}
foldchange_DP_N = meanDP - meanN
```

These reproduced fold changes can be compared to the probes listed in table S5.

```{r dev='png', fig.width=10, fig.height=5, fig.show='hold', tidy=FALSE}
par(mfrow=c(1, 2))
plot(table_s5$Fold_Change, foldchange_DP_N[table_s5$Probe],
     pch=".", xlab="Original Table S5", ylab="Reproduced",
     main="FC comparison")

thiscolors = c("black", "red")
hist(foldchange_DP_N, breaks=100, freq=F, border=thiscolors[1], main="Reproduced FC for DP vs. N")
hist(foldchange_DP_N[table_s5$Probe], breaks=100, add=T, freq=F, border=thiscolors[2])
legend("topright", legend=c("All probes", "Table S5 probes"), text.col=thiscolors)
```

The first plot reveals that the reproduced fold changes are much more compressed than the ones in Table S5.
There seems to be two linear relationship, one for negative FC's and another for positive FC's. They seem to have different intercepts, but comparable slope. The second plot shows that the reproduced fold changes for the probes listed in Table S5 are clearly more extreme than the rest.  

The fold changes in table 5S do not match the fold changes computed from the average expression values listed in table S2 either, as a plot will show;

```{r fc, dev='png', fig.width=8, fig.height=8, fig.show='hold', tidy=FALSE}
# table S2 has the AVG for both DP and N listed
fc_table_s2 = table_s2$AVG_GA - table_s2$AVG_generic
names(fc_table_s2) = table_s2$ID
x = table_s5$Fold_Change
y = fc_table_s2[table_s5$Probe]
lim =c( min(   c(min(x, na.rm=T), min(y, na.rm=T))  ), max( c(max(x, na.rm=T), max(y, na.rm=T)) ))
plot(x, y , ylim=lim, xlim=lim, pch="." ,  xlab="Table_S5", ylab="Table_S2",
     main="FC comparison, given values.") #  almost perfect match with offset.
rm(x, y, lim)
```

There seems to be some inconsistency between the fold changes in table S5 and the reproduced ones. However, it is the confidence i.e p-values that are affected by the use of ComBat. 

The rest of table S5 are p-values, and we will try to reproduce the ones from limma.

> Next, we utilized Linear Models for Microarray (LIMMA) data analysis [23], [24] R package, part of the Bioconductor framework [25], to compare generic and GA samples, fitting a linear model that adjusts for fixed effect from medium (Effect = (GA-generic) – (generic-Medium)). The coefficients for the linear model were tested for significance using a modified t-test (taking into account standard deviation)...<cite> Towfic et al.

The formula "Effect = (GA-generic) - (generic-Medium)" seems strange.

```{r dev='png', fig.width=10, fig.height=6, fig.show='hold', tidy=FALSE}
group = factor(sampleannotation$covariate)
design = model.matrix(~0 + group)
fit = lmFit(datamatrices[["real_combat_covariates"]], design)
cont.matrix = makeContrasts ( contrasts="(groupDP-groupN) - (groupN-groupM)", levels=design)  
fit2 = contrasts.fit(fit, cont.matrix)
limma_ret_org = eBayes(fit2)
limma_p_org = limma_ret_org$p.value
#names(limma_p_org) = names(limma_ret_org$Amean)
par(mfrow=c(1, 2))
plot(table_s5[,"limma_p"], limma_p_org[table_s5$Probe,1], xlab="Original Table S5", 
     ylab="Reproduced", main="LIMMA P-values from table S5 vs. reproduced")
thiscolors = c("black", "red")
hist(limma_p_org, breaks=100, freq=T, border=thiscolors[1], main="Reproduced LIMMA p-values for DP vs. N")
hist(limma_p_org[table_s5$Probe,1], breaks=100, add=T, freq=T, border=thiscolors[2])
legend("topright", legend=c("All probes", "Table S5 probes"), text.col=thiscolors)
```

A lot of the reproduced p-values are high for the probes in Table S5. A more straightforward contrast of Effect = GA-generic gives more similar p-values as in Table S5. We assume "GA-generic" or equivalent was used by Towfic et al., and for the remainder of this report, this is what will be used.

```{r dev='png', fig.width=10, fig.height=6, fig.show='hold', tidy=FALSE}
cont.matrix = makeContrasts ( contrasts="groupDP-groupN", levels=design)  
fit2 = contrasts.fit(fit, cont.matrix)
limma_ret_alt = eBayes(fit2)
limma_p_alt = limma_ret_alt$p.value
#names(limma_p_alt) = names(limma_ret_alt$Amean)
par(mfrow=c(1, 2))
plot(table_s5[,"limma_p"], limma_p_alt[table_s5$Probe,1], xlab="Original Table S5", 
     ylab="Reproduced", main="LIMMA P-values from table S5 vs. reproduced")
thiscolors = c("black", "red")
hist(limma_p_alt, breaks=100, freq=T, border=thiscolors[1], main="Reproduced LIMMA p-values for DP vs. N")
hist(limma_p_alt[table_s5$Probe,1], breaks=100, add=T, freq=T, border=thiscolors[2])
legend("topright", legend=c("All probes", "Table S5 probes"), text.col=thiscolors)
```

The reproduced p-values for the Table S5 probes are not exactly as the listed ones, but still mostly low. In addition to the limma test, Towfic et al. performed similar tests for significant probes between generic and GA using several other methods. We tried several of them as well, but have skipped them in this report, since they showed a similar pattern as for the limma p-values.

This concludes the reproduction. We managed to reproduce the average expressions listed in Table S2 pretty well. The p-values in Table S5 were with some reasonable interpretation reproduced. The results can now be compared to the same analysis using an alternative to ComBat.

<br/>
<br/>

### Analysis without ComBat, and consequences for the results

Table S2 has average expression values for the conditions, but includes no values about how much trust we can have in those average expressions (i.e significance tests, confidence intervals etc.).

Table S5, on the other hand, consists of results from significance tests that are strongly influenced by ComBat's data transformation. An alternative way of handling the batch effect compared to ComBat's is to include it in the statistical test. This can be done in limma in two ways. First what is described as "Blocking" in the limma user guide.

```{r limmacomparison, dev='png', fig.width=8, fig.height=8, fig.show='hold', tidy=FALSE}
group = factor(sampleannotation$covariate)
block = factor(sampleannotation$chip)
design = model.matrix(~0+group+block)
fit = lmFit(datamatrices[["real_qnorm"]], design)
cont.matrix = makeContrasts ( contrasts="groupDP-groupN", levels=design)  
fit2 = contrasts.fit(fit, cont.matrix)
#limma_ret_woc = eBayes(fit2)
#limma_p_woc = limma_ret_woc$p.value
#names(limma_p_woc) = names(limma_ret_woc$Amean)
limma_p_woc =  eBayes(fit2)$p.value
rm(design, group, block, fit, cont.matrix, fit2)
table(p.adjust(limma_p_alt , method="fdr")<0.05, p.adjust(limma_p_woc , method="fdr")<0.05, dnn=c("ComBat adj", "LIMMA adj"))
```

The number of significant probes using the given FDR threshold of 0.05 when batch effect is handled by LIMMA is 
**`r sum(p.adjust(limma_p_woc , method="fdr")<0.05)`**. This is much lower compared to when ComBat is applied (
**`r sum(p.adjust(limma_p_alt , method="fdr")<0.05)`** ).  The p-value distribution is still skewed, but not as much.

Alternatively, limma´s <i>duplicateCorrelation</i> function can be used to treat batch as a random effect. This could arguably be a more powerful approach, and a short investigation is warranted.

```{r limmacomp2, dev='png', fig.width=8, fig.height=8, fig.show='hold', tidy=FALSE}

group = factor(sampleannotation$covariate)
block = factor(sampleannotation$chip)
design = model.matrix(~0+group)

corfit <- duplicateCorrelation(datamatrices[["real_qnorm"]],design,block=block)
fit <- lmFit(datamatrices[["real_qnorm"]],design,block=block,correlation=corfit$consensus)
cont.matrix = makeContrasts ( contrasts="groupDP-groupN", levels=design)  
fit2 = contrasts.fit(fit, cont.matrix)
#limma_ret_woc = eBayes(fit2)
limma_p_mixed = eBayes(fit2)$p.value

thiscolors = c("red", "blue", "black")
hist(limma_p_alt, breaks=100, freq=T, border=thiscolors[1], main="Alternative P-value distributions for DP vs. N", xlab="P-values")
hist(limma_p_woc, breaks=100, add=T, freq=T, border=thiscolors[2])
hist(limma_p_mixed, breaks=100, add=T, freq=T, border=thiscolors[3])
legend("topright", legend=c("ComBat adjusted", "batch handled by LIMMA as factor", "batch handled by LIMMA as random effect"), text.col=thiscolors)
```

For this data set, the two LIMMA methods will give quite similar results, at least compared to the ComBat adjusted approach. We will only use the first, "Blocking", in subsequent comparisons.

<br/>
<br/>

### Additional sanity checks

To substantiate that the result from the use of ComBat is less trustworthy than the alternative analysis, we provide a couple of additional sanity checks.

<br/>
<br/>

**Random data**

First, we use random numbers drawn from the same distribution(mean=0, sd=1) regardless of batch or covariate, while retaining the batch/covariate design.

```{r}
set.seed(100)
datamatrices[["random_raw"]] = matrix(rnorm(length(datamatrices[["real_raw"]]), mean=0, sd=1), 
                                      nrow=nrow(datamatrices[["real_raw"]]), 
                                      ncol=ncol(datamatrices[["real_raw"]]), 
                                      dimnames=dimnames(datamatrices[["real_raw"]]))
datamatrices[["random_combat_covariates"]]= as.matrix(ComBat(dat=datamatrices[["random_raw"]],
                                                             batch=sampleannotation$chip, 
                                                             mod=combatmod, 
                                                             numCovs=NULL, 
                                                             par.prior=TRUE, 
                                                             prior.plots=FALSE))
```

limma is then used in 3 ways

- On the ComBat adjusted random numbers
- On the random numbers ignoring batch information
- On the random numbers including batch as a blocking factor


```{r}
group = factor(sampleannotation$covariate)
design = model.matrix(~0 + group)
cont.matrix = makeContrasts ( contrasts="groupDP-groupN", levels=design)


fit = lmFit(datamatrices[["random_combat_covariates"]], design)  
fit2 = contrasts.fit(fit, cont.matrix)
limma_p_rand_combat = eBayes(fit2)$p.value[,1]

fit = lmFit(datamatrices[["random_raw"]], design)  
fit2 = contrasts.fit(fit, cont.matrix)
limma_p_rand_nocombat = eBayes(fit2)$p.value[,1]


block = as.factor(sampleannotation$chip)
design = model.matrix(~0+group+block)
cont.matrix = makeContrasts ( contrasts="groupDP-groupN", levels=design)
fit = lmFit(datamatrices[["random_raw"]], design)  
fit2 = contrasts.fit(fit, cont.matrix)
limma_p_rand_batchblocked = eBayes(fit2)$p.value[,1]

```

```{r limmacomp3, dev='png', fig.width=8, fig.height=8, fig.show='hold', tidy=FALSE}
par(mfrow=c(1, 1))
thiscolors = c("red", "blue", "black")
hist(limma_p_rand_combat, breaks=100, freq=T, border=thiscolors[1], main="P-values, Random numbers for DP vs. N")
hist(limma_p_rand_nocombat, breaks=100, add=T, freq=T, border=thiscolors[2])
hist(limma_p_rand_batchblocked, breaks=100, add=T, freq=T, border=thiscolors[3])
legend("topright", legend=c("ComBat adjusted", "batch handled by Limma as factor", "No adjustment"), text.col=thiscolors)
```

The p-value plots from the ComBat adjusted random data shows a skewed distribution, although not as much as for the real data. The random data has no batch effect or other effects like the real data which might affect the ComBat adjustment.

<br/>
<br/>



```{r sessionInfo, comment=""}
sessionInfo()
```

generation ended `r as.character(Sys.time())`. Time spent `r  as.integer(round(difftime(Sys.time(),starttime, units="mins")))` minutes .


